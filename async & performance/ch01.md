# YDKJS Notes: Async & Performance
# Chapter 01: Asyncrony: Now & Later

## A program in chunk

In javascript programs runs in chunks. Which does not happen _now_ will might be happen _later_. We have to understand how those chunks are executed. The _later_ part will happen asyncronously.

*Warning:* It is possible to make syncronous ajax call, doing that is a very bad idea because that will break the UI components.

Anytime we wrap a portion of our program into a `function` and expect to run it after some time, we are creating asyncrony to our program.

### Async Chunk

The idea of `console.*` statement is not offical part of JavaScript. So many _hosting environment_ any implement `console` differently. Now the question is what exactly happen to the following code if `console` has been implented asyncronously?
```js
var a = {
    index: 1
};

console.log(a);

a.index++;
```

If for some reason any type of blocking happend then `console` (for asyncronous implementation) might output unexpected results.

## Event Loop

Up untill recently(ES6), JavaScript itself has actually never had any notion of asynchrony build into it.


Our JavaScript code runs in chucks that means it is not necessary that some arbitrary amount of code will definitely fire aftersome amount of code. Event loops is a queue that runs codes that are waiting to execute. Since it is a queue, other chunk of code might be in it before your arbitrary amount of code. They will execute first then after your code will run just like a queue works.

## Parallel Threading

It is common to conflate the word "async" and "paralled" together, but they are quite different. Remember async is about the gap between _now_ and _later_. But paralled is about things being able to occure simultaniously.

In paralled computing, processes and thread may execute simultaniously on same processor or even on different computers, but threads can share the memory of a single process.

An event loop break its work in tasks and execute them in serial.

In single thread environment it really don't matter the items of the thread queue are low-leven operations, because nothing can interrupt the thread. But if in parallel, where two different thread are oparating on a program, you could very likely have unpredictable behavior.

Consider:
```js
var a = 20;

function foo() {
	a = a + 1;
}

function bar() {
	a = a * 2;
}

// ajax(..) is some arbitrary Ajax function given by a library
ajax( "http://some.url.1", foo );
ajax( "http://some.url.2", bar );
```

In JavaScript's single threaded environment if `foo` runs first then result will be 42 but if `bar` runs first then result will be 41.

Now lets see what happen when we run it on paralled threaded environment.

Thread 1 (`X` and `Y` are temporary memory locations):
```
foo():
  a. load value of `a` in `X`
  b. store `1` in `Y`
  c. add `X` and `Y`, store result in `X`
  d. store value of `X` in `a`
```

Thread 2 (`X` and `Y` are temporary memory locations):
```
bar():
  a. load value of `a` in `X`
  b. store `2` in `Y`
  c. multiply `X` and `Y`, store result in `X`
  d. store value of `X` in `a`
```

Now let's see the two threads are running in paralled then you can see the problem, right?
What's the end result of `a` when steps happen like this?
```
1a  (load value of `a` in `X`   ==> `20`)
2a  (load value of `a` in `X`   ==> `20`)
1b  (store `1` in `Y`   ==> `1`)
2b  (store `2` in `Y`   ==> `2`)
1c  (add `X` and `Y`, store result in `X`   ==> `22`)
1d  (store value of `X` in `a`   ==> `22`)
2c  (multiply `X` and `Y`, store result in `X`   ==> `44`)
2d  (store value of `X` in `a`   ==> `44`)
``` 
The result in `a` will be 44. But what about this ordering?
```
1a  (load value of `a` in `X`   ==> `20`)
2a  (load value of `a` in `X`   ==> `20`)
2b  (store `2` in `Y`   ==> `2`)
1b  (store `1` in `Y`   ==> `1`)
2c  (multiply `X` and `Y`, store result in `X`   ==> `20`)
1c  (add `X` and `Y`, store result in `X`   ==> `21`)
1d  (store value of `X` in `a`   ==> `21`)
2d  (store value of `X` in `a`   ==> `21`)
```
The result in `a` will be 21.

So, threaded programming is very tricky with nondeterministic behavior.

But also keep not that in JavaScript nondeterministic isn't a concern but that doesn't mean that behavior is always deterministic. As executation of ordering of `foo` and `bar` has produced different results.

### Run-to-Completion
Because of JavaScript's single-threading, the code inside `foo()` and `bar()` is atomic. That means that once `foo()` starts running the entirety of its code will finish before any other code in `bar()` can run, or vice versa. This is called "run-to-completion" behavior.

As applied to JavaScript's behavior, this function-ordering nondeterminism is the common term "race condition," as `foo()` and `bar()` are racing against each other to see which runs first. Specifically, it's a "race condition" because you cannot predict reliably how a and b will turn out.

## Concurrency
Concurrency is when two or more "process" are executing simultaneously over the same period of time, regardless of their individual constituent operations happen in paralled (at the same instant on separate processors or cores) or not. You can think of concurrency then as "process"-level (or task-level) parallelism, as opposed to operation-level parallelism (separate-processor threads).

Let's say we have 2 process that runs concurrently.

"Process" 1 (`onscroll` event):
```
onscroll, request 1
onscroll, request 2
onscroll, request 3
onscroll, request 4
onscroll, request 5
onscroll, request 6
onscroll, request 7
```

"Process" 2 (Ajax response events):

```
response 1
response 2
response 3
response 4
response 5
response 6
response 7
```
It is quite possible that `onscroll` events and Ajax response could be ready to processed exactly the same time.
Let's visualize the event loop queue:
```
onscroll, request 1   <--- Process 1 starts
onscroll, request 2
response 1            <--- Process 2 starts
onscroll, request 3
response 2
response 3
onscroll, request 4
onscroll, request 5
onscroll, request 6
response 4
onscroll, request 7   <--- Process 1 finishes
response 6
response 5
response 7            <--- Process 2 finishes
```
### Noninteracting & Interaction
Consider this code:
```js
var res = {};

function foo(results) {
	res.foo = results;
}

function bar(results) {
	res.bar = results;
}

// ajax(..) is some arbitrary Ajax function given by a library
ajax( "http://some.url.1", foo );
ajax( "http://some.url.2", bar );
```
This is a noninteraction code because order of the concurrent "process" doesn't affect the desire outcome. We can say no "race-condition" bug.

Now consider this code:
```js
var res = [];

function response(data) {
	res.push( data );
}

// ajax(..) is some arbitrary Ajax function given by a library
ajax( "http://some.url.1", response );
ajax( "http://some.url.2", response );
```
Order of the responce matter in this case. Which ajax request finish first will be at `res[0]` and other at `res[1]`. We have to be careful because this will lead to "race-condition" bug.

So, to address such a race condition, you can coordinate ordering interaction:
```js
var res = [];

function response(data) {
	if (data.url == "http://some.url.1") {
		res[0] = data;
	}
	else if (data.url == "http://some.url.2") {
		res[1] = data;
	}
}

// ajax(..) is some arbitrary Ajax function given by a library
ajax( "http://some.url.1", response );
ajax( "http://some.url.2", response );
```
### Cooperation
In "cooperative concurrency" we take a long-running "process" and break it into steps or batches so ther other "processes" have a chance to interleave their operations into the event loop queue.

While processing big number of datas (e.g. 10 millions) it is very likely that our system will be forzen for some time. In order to handle this carefully, we make our programm more cooperatively.

Here's what we do:
```js
var res = [];

// `response(..)` receives array of results from the Ajax call
function response(data) {
	// let's just do 1000 at a time
	var chunk = data.splice( 0, 1000 );

	// add onto existing `res` array
	res = res.concat(
		// make a new transformed array with all `chunk` values doubled
		chunk.map( function(val){
			return val * 2;
		} )
	);

	// anything left to process?
	if (data.length > 0) {
		// async schedule next batch
		setTimeout( function(){
			response( data );
		}, 0 );
	}
}

// ajax(..) is some arbitrary Ajax function given by a library
ajax( "http://some.url.1", response );
ajax( "http://some.url.2", response );
```
But doing this, our output will not be predictable. If we want it to be predictable we will have to use the interaction technique that we've discuss earlier.
## Jobs
As of ES6, JavaScript has something call "Job queue".

It's kind like saying "oh, here is this other thing I need to do it later, but make sure it happens right away before anything else can happen.

Or, to use a metaphor: the event loop queue is like an amusement park ride, where once you finish the ride, you have to go to the back of the line to ride again. But the Job queue is like finishing the ride, but then cutting in line and getting right back on.

Consider this:
```js
console.log( "A" );

setTimeout( function(){
	console.log( "B" );
}, 0 );

// theoretical "Job API"
schedule( function(){
	console.log( "C" );

	schedule( function(){
		console.log( "D" );
	} );the 
} );
```
You might expect this print out `A B C D`, but actually it would print `A C D B`, because the job happens at the end of the current loop.
## Review
A JavaScript program is (practically) always broken up into two or more chunks, where the first chunk runs now and the next chunk runs later, in response to an event. Even though the program is executed chunk-by-chunk, all of them share the same access to the program scope and state, so each modification to state is made on top of the previous state.

Whenever there are events to run, the event loop runs until the queue is empty. Each iteration of the event loop is a "tick." User interaction, IO, and timers enqueue events on the event queue.

At any given moment, only one event can be processed from the queue at a time. While an event is executing, it can directly or indirectly cause one or more subsequent events.

Concurrency is when two or more chains of events interleave over time, such that from a high-level perspective, they appear to be running simultaneously (even though at any given moment only one event is being processed).

It's often necessary to do some form of interaction coordination between these concurrent "processes" (as distinct from operating system processes), for instance to ensure ordering or to prevent "race conditions." These "processes" can also cooperate by breaking themselves into smaller chunks and to allow other "process" interleaving.
